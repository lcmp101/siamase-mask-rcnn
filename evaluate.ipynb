{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%load_ext line_profiler\n",
    "\n",
    "import sys\n",
    "import os\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n",
    "os.environ['LD_LIBRARY_PATH']='/data/lmp/anaconda3/envs/siamese-mask-rcnn/lib/'\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess_config = tf.ConfigProto()\n",
    "\n",
    "COCO_DATA = 'data/coco/'\n",
    "MASK_RCNN_MODEL_PATH = 'lib/Mask_RCNN/'\n",
    "\n",
    "if MASK_RCNN_MODEL_PATH not in sys.path:\n",
    "    sys.path.append(MASK_RCNN_MODEL_PATH)\n",
    "    \n",
    "from samples.coco import coco\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "    \n",
    "from lib import utils as siamese_utils\n",
    "from lib import model as siamese_model\n",
    "from lib import config as siamese_config\n",
    "   \n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import imgaug\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classes = coco_nopascal_classes\n",
    "train_classes = np.array(range(1,81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.40s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load COCO/val dataset\n",
    "coco_val = siamese_utils.IndexedCocoDataset()\n",
    "coco_object = coco_val.load_coco(COCO_DATA, \"val\", year=\"2017\", return_coco=True)\n",
    "coco_val.prepare()\n",
    "coco_val.build_indices()\n",
    "coco_val.ACTIVE_CLASSES = train_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallEvalConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'evaluation'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    NUM_TARGETS = 1\n",
    "    \n",
    "class LargeEvalConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'evaluation'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    NUM_TARGETS = 1\n",
    "    \n",
    "    # Large image sizes\n",
    "    TARGET_MAX_DIM = 192\n",
    "    TARGET_MIN_DIM = 150\n",
    "    IMAGE_MIN_DIM = 800\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Large model size\n",
    "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
    "    FPN_FEATUREMAPS = 256\n",
    "    # Large number of rois at all stages\n",
    "    RPN_ANCHOR_STRIDE = 1\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 1000\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    MAX_GT_INSTANCES = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select small or large model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The small model trains on a single GPU and runs much faster.\n",
    "# The large model is the same we used in our experiments but needs multiple GPUs and more time for training.\n",
    "model_size = 'small' # or 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "CHECKPOINT_DIR                 checkpoints/\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        30\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.5\n",
      "EXPERIMENT                     evaluation\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     512\n",
      "FPN_FEATUREMAPS                256\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  400\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.02\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 2.0, 'rpn_bbox_loss': 0.1, 'mrcnn_class_loss': 2.0, 'mrcnn_bbox_loss': 0.5, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               30\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "MODEL                          mrcnn\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    2\n",
      "NUM_TARGETS                    1\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        500\n",
      "POST_NMS_ROIS_TRAINING         500\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                1000\n",
      "TARGET_MAX_DIM                 96\n",
      "TARGET_MIN_DIM                 75\n",
      "TARGET_PADDING                 True\n",
      "TARGET_SHAPE                   [96 96  3]\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           100\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n"
     ]
    }
   ],
   "source": [
    "if model_size == 'small':\n",
    "    config = SmallEvalConfig()\n",
    "elif model_size == 'large':\n",
    "    config = LargeEvalConfig()\n",
    "    \n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide training schedule of the model\n",
    "# When evaluationg intermediate steps the tranining schedule must be provided\n",
    "train_schedule = OrderedDict()\n",
    "if model_size == 'small':\n",
    "    train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
    "    train_schedule[120] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"4+\"}\n",
    "    train_schedule[160] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}\n",
    "elif model_size == 'large':\n",
    "    train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
    "    train_schedule[240] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"all\"}\n",
    "    train_schedule[320] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select checkpoint\n",
    "if model_size == 'small':\n",
    "    checkpoint = 'checkpoints/small_siamese_mrcnn_0160.h5'\n",
    "elif model_size == 'large':\n",
    "    checkpoint = 'checkpoints/large_siamese_mrcnn_coco_full_0320.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoints/small_siamese_mrcnn_0160.h5 ...\n",
      "starting from epoch 160\n",
      "starting evaluation ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.70s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
      "Prediction time: 265.84666681289673. Average 0.2658466668128967/image\n",
      "Total time:  595.7348160743713\n"
     ]
    }
   ],
   "source": [
    "# Load and evaluate model\n",
    "# Create model object in inference mode.\n",
    "model = siamese_model.SiameseMaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_checkpoint(checkpoint, training_schedule=train_schedule)\n",
    "# Evaluate only active classes\n",
    "active_class_idx = np.array(coco_val.ACTIVE_CLASSES) - 1\n",
    "\n",
    "# Evaluate on the validation set\n",
    "print('starting evaluation ...')\n",
    "siamese_utils.evaluate_dataset(model, coco_val, coco_object, eval_type=\"bbox\", \n",
    "                 dataset_type='coco', limit=1000, image_ids=None, \n",
    "                 class_index=active_class_idx, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoints/small_siamese_mrcnn_0160.h5 ...\n",
      "starting from epoch 160\n",
      "starting evaluation ...\n"
     ]
    }
   ],
   "source": [
    "config.NUM_TARGETS = 5\n",
    "# Load and evaluate model\n",
    "# Create model object in inference mode.\n",
    "model = siamese_model.SiameseMaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_checkpoint(checkpoint, training_schedule=train_schedule)\n",
    "# Evaluate only active classes\n",
    "active_class_idx = np.array(coco_val.ACTIVE_CLASSES) - 1\n",
    "\n",
    "# Evaluate on the validation set\n",
    "print('starting evaluation ...')\n",
    "siamese_utils.evaluate_dataset(model, coco_val, coco_object, eval_type=\"bbox\", \n",
    "                 dataset_type='coco', limit=1000, image_ids=None, \n",
    "                 class_index=active_class_idx, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = siamese_model.SiameseMaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_checkpoint(checkpoint, training_schedule=train_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Select category\n",
    "category = 1\n",
    "image_id = np.random.choice(coco_val.category_image_index[category])   \n",
    "# Load target\n",
    "target = siamese_utils.get_one_target(category, coco_val, config)\n",
    "# Load image\n",
    "image = coco_val.load_image(image_id)\n",
    "print(\"image_id\", image_id)\n",
    "\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([[target]], [image], verbose=1)\n",
    "r = results[0]\n",
    "# Display results\n",
    "siamese_utils.display_results(target, image, r['rois'], r['masks'], r['class_ids'], r['scores'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
